# Retinal-NeuralNET

This repository contains a comprehensive deep learning framework for **retinal fundus multi-disease detection** using both Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). The project focuses on comparing different deep learning architectures for classifying retinal diseases from fundus images using the RFMiD (Retinal Fundus Multi-Disease Image Dataset). The research is based on the following articles:

[**"Research Article on Thyroid Nodule Classification"**](https://www.sciencedirect.com/science/article/pii/S1877050924031235)
[**"Evaluating the Performance and Clinical Applications of Multiclass Deep Learning Models for Skin Cancer Pathology Diagnosis (ISIC): A Comparative Analysis of CNN, ViT, and VLM"**](https://dl.acm.org/doi/10.1145/3731763.3731793)
[**"Retinal Fundus Multi-Disease Image Dataset (RFMiD): A Dataset for Multi-Disease Detection Research"**](https://ieee-dataport.org/open-access/retinal-fundus-multi-disease-image-dataset-rfmid)
[**"Comparative Analysis of Vision Transformers and Conventional Convolutional Neural Networks in Detecting Referable Diabetic Retinopathy"**](https://www.ophthalmologyscience.org/article/S2666-9145(24)00088-5/fulltext)

---

## üéØ Project Overview

This project implements **multi-label retinal disease classification** using both CNN and Vision Transformer architectures:

### **Primary Focus: Retinal Disease Detection**
- **Task**: Multi-label classification of retinal diseases from fundus images
- **Dataset**: RFMiD Challenge Dataset (3,200 fundus images)
- **Diseases**: 29 different retinal disease categories
- **CNN Architectures**: ResNet50, DenseNet121, InceptionV3, EfficientNet-B3
- **ViT Architecture**: Vision Transformer (ViT) for comparison
- **Analysis**: Comprehensive statistical comparison using Delong and McNemar tests

### **Key Features**
- Multi-label disease classification (29 disease categories)
- CNN vs ViT architecture comparison and benchmarking
- Statistical significance testing
- Comprehensive evaluation metrics (AUC, Sensitivity, Specificity, F1-Score)
- Clinical-grade performance analysis
- Both retinal fundus and thyroid nodule classification capabilities

---

## üõ†Ô∏è Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/Durjoy001/Retinal-NeuralNET
cd Retinal-NeuralNET
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run Retinal Disease Classification

**CNN Training:**
```bash
python src/train_cnn.py
```

**Vision Transformer Training:**
```bash
python misc/main.py
```

### 4. Generate Visualizations
```bash
python src/visualize_data.py
```

---

## üìä Dataset Information

### **RFMiD Retinal Fundus Dataset**
- **Format**: PNG fundus images with CSV labels
- **Size**: 3,200 retinal fundus images
  - Training: 1,920 images
  - Validation: 640 images  
  - Testing: 640 images
- **Resolution**: High-resolution fundus photographs
- **Labels**: Multi-label annotations for 29 disease categories

### **Retinal Disease Categories (29 total)**
| Disease | Full Name | Cases | % |
|---------|-----------|-------|---|
| DR | Diabetic Retinopathy | 376 | 19.6% |
| ARMD | Age-related Macular Degeneration | 100 | 5.2% |
| MH | Macular Hole | 317 | 16.5% |
| MYA | Myopia | 101 | 5.3% |
| BRVO | Branch Retinal Vein Occlusion | 73 | 3.8% |
| TSLN | Tessellated Fundus | 186 | 9.7% |
| ODC | Optic Disc Cupping | 282 | 14.7% |
| *...and 22 other retinal conditions* | | | |

---

## üèóÔ∏è Architecture Comparison

### **CNN Models Evaluated**
1. **ResNet50** - Residual Network with 50 layers
2. **DenseNet121** - Densely Connected Convolutional Network
3. **InceptionV3** - Inception Network Version 3
4. **EfficientNet-B3** - EfficientNet with compound scaling

### **Vision Transformer Models**
1. **ViT-Tiny** - Vision Transformer with tiny patch size (16x16)
2. **ViT-Base** - Standard Vision Transformer architecture

### **Training Configuration**
- **Batch Size**: 16
- **Epochs**: 20 (with early stopping)
- **Learning Rate**: 1e-4
- **Optimizer**: Adam with differential learning rates
- **Loss Function**: BCEWithLogitsLoss with class weighting
- **Data Augmentation**: Random horizontal flipping
- **Early Stopping**: Patience of 5 epochs

---

## üìà Results and Performance

### **CNN Architecture Performance Comparison**

| Rank | Architecture | Test AUC | Sensitivity | Specificity | Balanced Accuracy |
|------|--------------|----------|-------------|-------------|-------------------|
| ü•á | **ResNet50** | **0.873** | **0.805** | **0.883** | **0.844** |
| ü•à | DenseNet121 | 0.857 | 0.788 | 0.887 | 0.837 |
| ü•â | EfficientNet-B3 | 0.843 | 0.814 | 0.850 | 0.832 |
| 4th | InceptionV3 | 0.810 | 0.745 | 0.844 | 0.794 |

### **Key Findings**
- **ResNet50** achieves the best overall performance across all metrics
- **Statistical Significance**: Delong and McNemar tests confirm ResNet50 is significantly better than all other architectures (p < 0.001)
- **Clinical Relevance**: High specificity (88.3%) reduces false positives in clinical screening
- **Balanced Performance**: Good sensitivity (80.5%) ensures most diseases are detected
- **Consistent Performance**: All models show strong clinical-grade performance (>80% AUC)

---

## üî¨ Statistical Analysis

### **Delong Test Results**
- **Purpose**: Compare AUC differences between architectures
- **Key Findings**: 
  - ResNet50 significantly outperforms all other models (p < 0.001)
  - DenseNet121 vs EfficientNet-B3: p = 0.0002 (significant)
  - DenseNet121 vs InceptionV3: p = 0.026 (significant)
  - EfficientNet-B3 vs InceptionV3: p = 0.425 (not significant)
- **Significance Level**: Œ± = 0.05

### **McNemar Test Results**  
- **Purpose**: Test classification accuracy differences
- **Key Findings**:
  - ResNet50 shows significant accuracy improvements over all models (p < 0.001)
  - DenseNet121 vs EfficientNet-B3: p = 0.023 (significant)
  - EfficientNet-B3 vs InceptionV3: p = 0.193 (not significant)
- **Clinical Impact**: Validates superior diagnostic performance of ResNet50

---

## üìÅ Project Structure

```
Retinal-NeuralNET/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ RFMiD_Challenge_Dataset/          # Retinal fundus dataset
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1. Original Images/           # Training, validation, test images
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 2. Groundtruths/              # CSV labels for all splits
‚îÇ   ‚îî‚îÄ‚îÄ External_Dataset/                  # Additional datasets
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ train_cnn.py                      # Multi-CNN training script
‚îÇ   ‚îî‚îÄ‚îÄ visualize_data.py                 # Results visualization
‚îú‚îÄ‚îÄ misc/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                           # Main entry point for ViT training
‚îÇ   ‚îú‚îÄ‚îÄ train_vit.py                      # Vision Transformer training
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                        # Dataset utilities
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                          # Utility scripts
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îî‚îÄ‚îÄ CNN/                              # CNN model results
‚îÇ       ‚îú‚îÄ‚îÄ ResNet50/                     # Best performing model
‚îÇ       ‚îú‚îÄ‚îÄ Densenet121/                  # Second best
‚îÇ       ‚îú‚îÄ‚îÄ InceptionV3/                  # Third best  
‚îÇ       ‚îî‚îÄ‚îÄ EfficientNetB3/               # Fourth best
‚îú‚îÄ‚îÄ statistical_tests/                    # Statistical analysis results
‚îÇ   ‚îú‚îÄ‚îÄ delong_test_results.csv           # Delong test results
‚îÇ   ‚îú‚îÄ‚îÄ mcnemar_test_results.csv          # McNemar test results
‚îÇ   ‚îî‚îÄ‚îÄ statistical_tests.py              # Statistical test implementation
‚îî‚îÄ‚îÄ requirements.txt                      # Python dependencies
```

---

## üìä Output Files

### **Per-Model Results**
Each CNN architecture generates:
- **Model Checkpoint**: Best performing model (`.pth`)
- **Training Curves**: Loss and accuracy progression
- **Metrics CSV**: Detailed per-epoch performance
- **Test Results**: Final evaluation metrics
- **Statistical Data**: NPZ files for statistical tests

### **Visualization Outputs**
- Overall performance comparison charts
- Per-disease sensitivity/specificity plots
- Top performing disease analysis
- Performance distribution histograms

---

## ‚öôÔ∏è Configuration

### **Reproducibility**
- Python: `random.seed(42)`
- NumPy: `np.random.seed(42)`
- PyTorch: `torch.manual_seed(42)`
- CUDA: Deterministic operations enabled

### **Hardware Requirements**
- **GPU**: Recommended for CNN training (CUDA support)
- **Memory**: 8GB+ RAM recommended
- **Storage**: ~2GB for dataset
- **CPU**: Multi-core recommended for data loading

---

## üöÄ Quick Start

1. **Setup**:
   ```bash
   git clone https://github.com/Durjoy001/Retinal-NeuralNET
   cd Retinal-NeuralNET
   pip install -r requirements.txt
   ```

2. **Train Models**:
   
   **CNN Models:**
   ```bash
   python src/train_cnn.py
   ```
   
   **Vision Transformer:**
   ```bash
   python misc/main.py
   ```

3. **View Results**:
   ```bash
   python src/visualize_data.py
   ```

4. **Run Statistical Tests**:
   ```bash
   python statistical_tests/statistical_tests.py
   ```

---

## üéØ Disease-Specific Performance (ResNet50)

### **Top Performing Diseases**
| Disease | Sensitivity | Specificity | Clinical Significance |
|---------|-------------|-------------|----------------------|
| MYA (Myopia) | 100.0% | 93.8% | Excellent detection |
| CSR (Central Serous Retinopathy) | 100.0% | 89.3% | Perfect sensitivity |
| RS (Retinal Spots) | 100.0% | 84.3% | High detection rate |
| MH (Macular Hole) | 97.1% | 81.0% | Strong performance |
| ARMD (Age-related Macular Degeneration) | 93.5% | 85.2% | Clinical-grade detection |

### **Challenging Diseases**
| Disease | Sensitivity | Specificity | Notes |
|---------|-------------|-------------|-------|
| ST (Subretinal Tissue) | 0.0% | 84.2% | Rare condition |
| AION (Anterior Ischemic Optic Neuropathy) | 25.0% | 95.4% | Low prevalence |
| PT (Parafoveal Telangiectasia) | 25.0% | 100.0% | High specificity |

---

## üìù Clinical Applications

This project provides:
- **Automated Retinal Disease Screening**: Multi-disease detection from fundus images with 29 disease categories
- **Architecture Benchmarking**: Evidence-based model selection for clinical deployment
- **Statistical Validation**: Rigorous performance comparison with clinical significance testing
- **Research Foundation**: Comprehensive framework for retinal disease classification research
- **Multi-Modal Analysis**: Both CNN and Vision Transformer approaches for comprehensive evaluation
- **Clinical-Grade Performance**: All models achieve >80% AUC, suitable for clinical screening applications

---

## üß™ Reproducibility

To ensure reproducibility, the following seeds are fixed:

- Python `random.seed(42)`
- NumPy `np.random.seed(42)`
- PyTorch `torch.manual_seed(42)`
